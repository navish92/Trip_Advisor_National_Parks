{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your Personal Trip Advisor\n",
    "#### Recommending attractions in Yosemite National Park based on personal preferences, by referencing reviews written by users on Trip Advisor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 of 4\n",
    "\n",
    "**Objective**\n",
    "In this notebook, we will clean the reviews in various ways, that have been scrapped from Trip Advisor. The aim is to optimize the corpus for topic modeling towards the overall project objectives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize, wordpunct_tokenize, sent_tokenize, RegexpTokenizer, regexp_tokenize, WhitespaceTokenizer\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.tag import pos_tag\n",
    "import spacy\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, ENGLISH_STOP_WORDS\n",
    "\n",
    "#Custom python module to help clean the text here\n",
    "import nlp_preprocessing\n",
    "\n",
    "spacy_nlp = spacy.load('en')\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 50)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10725, 11)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../Data/attraction_point_reviews.csv\")\n",
    "df.sample()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the Text "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To get an initial feel for the data, the following steps are being undertaken:\n",
    "1. All reviews are combined into a giant single string corpus.\n",
    "1. All words are changed to lower letter case\n",
    "1. website links & email ids are dropped\n",
    "1. A lot of words are wrongly connected with punctuations. Simply dropping the punctuations will connect these words. Instead, these will be substituted with whitespace for the following punctuations: <.*?>;-!()/,:&—\\ \n",
    "1. Everything, except for letters & whitespace, is dropped with no substitutions in between.\n",
    "1. The string is tokenized on whitespace.\n",
    "1. It is then converted into a word counter using FreqDist to explore frequencies and look at the various words used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_reviews = ' '.join(df.review_text.tolist())\n",
    "all_reviews = all_reviews.lower()\n",
    "all_reviews = re.sub('http\\S+', '' , all_reviews)\n",
    "all_reviews = re.sub('\\S*@\\S+', '', all_reviews)\n",
    "\n",
    "all_reviews = re.sub(r'[<.*?>;\\-!()/,:&—\\\\]+', ' ', all_reviews)\n",
    "all_reviews = re.sub(r'[^A-Za-z\\s]', '', all_reviews)\n",
    "words = WhitespaceTokenizer().tokenize(all_reviews)\n",
    "words_count = FreqDist(words)\n",
    "\n",
    "long_words = [w for w in words_count if len(w) > 15]\n",
    "small_words = [w for w in words_count if len(w) < 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above process was carried out iteratively to ensure as many long words as possible can be captured properly and not words arbitrarily combined together using punctuations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The cleaning strategy was applied to the reviews in the dataframe.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1202    having visited all of the major parks in the us  trekking the himalayas   and touring europe  asia  and africa  this ranks in the top ten spots  parking can be difficult  we had a handicap parking permit  and drove another couple about a mile to their car  the parks department is missing a marketing opportunity  by not having cast models of half dome  or the vista  not crowded walking around  very limited cell phone service for those who need to be connected  with all the hiking trails  i would think this could be a safety issue  no sympathy for just those who are addicted to being connected however  \n",
       "Name: reviews_basic_clean, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['reviews_basic_clean'] = df.review_text.map(nlp_preprocessing.cleaning)\n",
    "df.reviews_basic_clean.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The words are then lemmatized after cleaning, to reduce the variety of words itself in the corpus. Additionally, all pronouns are dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df['review_lemma'] = df.reviews_basic_clean.apply(nlp_preprocessing.spacy_lemmatization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_lemma</th>\n",
       "      <th>reviews_basic_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8312</th>\n",
       "      <td>park  car at the parking lot close to the village store and take a walk to the low waterfall   to minimize walk  can also take the free shuttle to bus stop      be approx    minute   one way   through pave but in some part snowy trail with awesome view   especially from the small bridge where the flow river be partly freeze   the fall be greatly pour and splash water to the surround area   include the bridge   despite the warning   a few visitor be climb the rock try to get close to the fall</td>\n",
       "      <td>we parked our car at the parking lot close to the village store and took a walk to the lower waterfall  to minimize walking you can also take the free shuttle to bus stop    it was approx   minutes  one way  through paved but in some parts snowy trail with awesome view  especially from the small bridges where the flowing river was partly frozen  the fall was greatly pouring and splashing water to the surrounding areas  including the bridge  despite the warning  a few visitors were climbing the rocks trying to get close to the fall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7893</th>\n",
       "      <td>this be a difficult hike because the trail be full of large stone in most place   still   the reward from the top of the fall be magnificent and well worth do</td>\n",
       "      <td>this is a difficult hike because the trail is full of large stones in most places  still  the reward from the top of the falls is magnificent and well worth doing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           review_lemma  \\\n",
       "8312   park  car at the parking lot close to the village store and take a walk to the low waterfall   to minimize walk  can also take the free shuttle to bus stop      be approx    minute   one way   through pave but in some part snowy trail with awesome view   especially from the small bridge where the flow river be partly freeze   the fall be greatly pour and splash water to the surround area   include the bridge   despite the warning   a few visitor be climb the rock try to get close to the fall   \n",
       "7893                                                                                                                                                                                                                                                                                                                                                     this be a difficult hike because the trail be full of large stone in most place   still   the reward from the top of the fall be magnificent and well worth do   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            reviews_basic_clean  \n",
       "8312  we parked our car at the parking lot close to the village store and took a walk to the lower waterfall  to minimize walking you can also take the free shuttle to bus stop    it was approx   minutes  one way  through paved but in some parts snowy trail with awesome view  especially from the small bridges where the flowing river was partly frozen  the fall was greatly pouring and splashing water to the surrounding areas  including the bridge  despite the warning  a few visitors were climbing the rocks trying to get close to the fall   \n",
       "7893                                                                                                                                                                                                                                                                                                                                                                                        this is a difficult hike because the trail is full of large stones in most places  still  the reward from the top of the falls is magnificent and well worth doing   "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['review_lemma','reviews_basic_clean']].sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Standard Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_remove_stop_words</th>\n",
       "      <th>review_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10659</th>\n",
       "      <td>wonderful hike snow melt away hike late spring worth bit challenging people not use altitude hiking just time step rail way</td>\n",
       "      <td>a wonderful hike after the snow melts away.  We have done this hike in late spring and it was well worth it.  It is a bit challenging for people not used to altitude or hiking, just take your time, it has steps and railing most of the way up.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>book tour glacier point driver guide collette knoweldgeable entertaining time great view point picnic just time eat picnic explore point coach trip</td>\n",
       "      <td>WE booked a tour to Glacier Point. Our driver and guide, Collette was very knoweldgeable and entertaining at times!! Great views at the point - we took a picnic but only just had enough time to eat our picnic and explore the point before the coach trip back down.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                  review_remove_stop_words  \\\n",
       "10659                          wonderful hike snow melt away hike late spring worth bit challenging people not use altitude hiking just time step rail way   \n",
       "129    book tour glacier point driver guide collette knoweldgeable entertaining time great view point picnic just time eat picnic explore point coach trip   \n",
       "\n",
       "                                                                                                                                                                                                                                                                   review_text  \n",
       "10659                     a wonderful hike after the snow melts away.  We have done this hike in late spring and it was well worth it.  It is a bit challenging for people not used to altitude or hiking, just take your time, it has steps and railing most of the way up.    \n",
       "129    WE booked a tour to Glacier Point. Our driver and guide, Collette was very knoweldgeable and entertaining at times!! Great views at the point - we took a picnic but only just had enough time to eat our picnic and explore the point before the coach trip back down.  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_stop_words = sorted(list(ENGLISH_STOP_WORDS))\n",
    "\n",
    "#removing the below stop words since they might denote a negative sentiment that is relevant towards reviews\n",
    "words_to_remove_from_stop_list = ['again','against','no', 'not',]\n",
    "\n",
    "sklearn_stop_words = [word for word in sklearn_stop_words if word not in words_to_remove_from_stop_list]\n",
    "\n",
    "df['review_remove_stop_words'] = df.review_lemma.map(lambda x: nlp_preprocessing.remove_stopwords(x, sklearn_stop_words ))\n",
    "\n",
    "df[['review_remove_stop_words','review_text']].sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['glacier', 'point', 'yosemite', 'valley', 'mariposa', 'grove', 'of', 'giant', 'sequoias', 'half', 'dome', 'tunnel', 'tioga', 'pass', 'el', 'capitan', 'mist', 'yosemite', 'vernal']\n"
     ]
    }
   ],
   "source": [
    "# Making a list of custom stop words from the names of the attractions, to remove from the corpus\n",
    "\n",
    "landmarks = df.attraction_name.unique().tolist()\n",
    "landmark_string = \" \".join(landmarks)\n",
    "landmark_words = landmark_string.lower().split()\n",
    "\n",
    "landmark_words.remove('trail')\n",
    "landmark_words.remove('view')\n",
    "landmark_words.remove('falls')\n",
    "landmark_words.remove('fall')\n",
    "\n",
    "print(landmark_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>review_remove_additional_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1661</th>\n",
       "      <td>Incredible views of mountains with a bit of a hike to get there; tough if you get short of breath easily as the elevation is 7000+</td>\n",
       "      <td>incredible view mountain hike tough short breath easily elevation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2306</th>\n",
       "      <td>Only just enough parking so don’t arrive too late if going for the day. Misty trail exillerating. Amazing waterfalls and rainbow in the mist. It is quite strenuous for a 60 year old with lots of steps up to the second waterfall. A poncho could be useful in cooler weather. Ok when it’s warm as the mist cools you down and you soon dry off. Mirror Lake is a mirror at the moment but later in the summer I would think there wouldn’t be enough water to create the mirror effect. The path on the right of the lake going further up the valley was flooded so we had to clamber over boulders and fallen trees on a very indistinct path. Later on that path we came across a bear! We were glad we hadn’t bumped into when clambering. I was surprised there were not many wardens/rangers around or a notice to inform us the path was flooded. Restrooms could be more signposted or even marked on given map. Would also be helpful if they were open!!!Pizza restaurant very reasonably priced.</td>\n",
       "      <td>just parking not arrive late day misty trail exillerate amazing waterfall rainbow quite strenuous old lot step second waterfall poncho useful cooler weather ok warm cool soon dry mirror lake mirror moment later summer not water create mirror effect path right lake far flood clamber boulder fall tree indistinct path later path come bear glad not bump clamber surprised not warden ranger notice inform path flood restroom signposted mark map helpful open pizza restaurant reasonably price</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          review_text  \\\n",
       "1661                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Incredible views of mountains with a bit of a hike to get there; tough if you get short of breath easily as the elevation is 7000+   \n",
       "2306  Only just enough parking so don’t arrive too late if going for the day. Misty trail exillerating. Amazing waterfalls and rainbow in the mist. It is quite strenuous for a 60 year old with lots of steps up to the second waterfall. A poncho could be useful in cooler weather. Ok when it’s warm as the mist cools you down and you soon dry off. Mirror Lake is a mirror at the moment but later in the summer I would think there wouldn’t be enough water to create the mirror effect. The path on the right of the lake going further up the valley was flooded so we had to clamber over boulders and fallen trees on a very indistinct path. Later on that path we came across a bear! We were glad we hadn’t bumped into when clambering. I was surprised there were not many wardens/rangers around or a notice to inform us the path was flooded. Restrooms could be more signposted or even marked on given map. Would also be helpful if they were open!!!Pizza restaurant very reasonably priced.   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                review_remove_additional_words  \n",
       "1661                                                                                                                                                                                                                                                                                                                                                                                                                                         incredible view mountain hike tough short breath easily elevation  \n",
       "2306  just parking not arrive late day misty trail exillerate amazing waterfall rainbow quite strenuous old lot step second waterfall poncho useful cooler weather ok warm cool soon dry mirror lake mirror moment later summer not water create mirror effect path right lake far flood clamber boulder fall tree indistinct path later path come bear glad not bump clamber surprised not warden ranger notice inform path flood restroom signposted mark map helpful open pizza restaurant reasonably price  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "additional_removal_words = ['washburn', 'lower', 'upper', 'worth', 'muir', 'john', 'sentinel', \\\n",
    "                            'columbia',  'nevada', 'vernall', 'park', 'national', 'think', 'want', \\\n",
    "                            'feel', 'thing', 'say', 'year', 'pm', 'bridal' , 'like', 'veil', 'bit', 'san' , \\\n",
    "                            'redwood', 'sequoia', 'wawona', 'toulumne', 'tahoe', 'tenaya', 'lee',\\\n",
    "                           'meadow', 'olmstead', 'pass', 'elcapitan' , 'tuolumne']\n",
    "\n",
    "       \n",
    "additional_removal_words.extend(landmark_words)\n",
    "\n",
    "df['review_remove_additional_words'] = df.review_remove_stop_words.map(\n",
    "    lambda x: nlp_preprocessing.remove_stopwords(x, additional_removal_words ))\n",
    "\n",
    "df[['review_text', 'review_remove_additional_words']].sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlook Sentiment\n",
    "Using the ratings to get a binary outlook sentiment from ratings, for Logistic Regression & Scattertext plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Outlook_Sentiment'] = df.rating.map(lambda x: 'Positive' if x >= 4 else 'Negative')\n",
    "df['outlook_sentiment_number'] = df.rating.map(lambda x: 1 if x >= 4 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Reviews_cleaned_for_NLP.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text has now been preprocessed and is ready for topic modeling.  \n",
    "Helper functions mentioned in this notebook can be found in the [nlp_preprocessing](nlp_preprocessing.py) python file.\n",
    "\n",
    "Additional pre-processing steps have been mentioned below for future reference. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For future work, the following cleaning can also be undertaken:\n",
    "1. letter repeats (tweet tokenizer & Crazy Tokenizer)\n",
    "1. Spell Check\n",
    "1. Different languages\n",
    "1. Named Entity Extraction\n",
    "3. Identifying actual hypentated words instead of separating them \n",
    "1. Removing words that are less than 4 letters perhaps - but selectively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring the reviews for entities that are present and seeing what can be dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['the', 'the', 'DET', ''],\n",
       " ['mist', 'mist', 'PROPN', ''],\n",
       " ['trail', 'trail', 'NOUN', ''],\n",
       " ['was', 'be', 'AUX', ''],\n",
       " ['an', 'an', 'DET', ''],\n",
       " ['adventure', 'adventure', 'NOUN', ''],\n",
       " ['we', '-PRON-', 'PRON', ''],\n",
       " ['all', 'all', 'DET', ''],\n",
       " ['enjoyed', 'enjoy', 'VERB', ''],\n",
       " [' ', ' ', 'SPACE', ''],\n",
       " ['from', 'from', 'ADP', ''],\n",
       " ['ages', 'age', 'NOUN', ''],\n",
       " [' ', ' ', 'SPACE', ''],\n",
       " ['to', 'to', 'PART', ''],\n",
       " ['  ', '  ', 'SPACE', ''],\n",
       " ['the', 'the', 'DET', ''],\n",
       " ['steps', 'step', 'NOUN', ''],\n",
       " ['up', 'up', 'ADV', ''],\n",
       " ['were', 'be', 'AUX', ''],\n",
       " ['super', 'super', 'ADV', ''],\n",
       " ['wet', 'wet', 'ADJ', ''],\n",
       " ['and', 'and', 'CCONJ', ''],\n",
       " ['a', 'a', 'DET', ''],\n",
       " ['bit', 'bit', 'ADV', ''],\n",
       " ['scary', 'scary', 'ADJ', ''],\n",
       " [' ', ' ', 'SPACE', ''],\n",
       " ['but', 'but', 'CCONJ', ''],\n",
       " ['with', 'with', 'ADP', ''],\n",
       " ['careful', 'careful', 'ADJ', ''],\n",
       " ['footing', 'footing', 'NOUN', ''],\n",
       " [' ', ' ', 'SPACE', ''],\n",
       " ['you', '-PRON-', 'PRON', ''],\n",
       " ['can', 'can', 'VERB', ''],\n",
       " ['do', 'do', 'AUX', ''],\n",
       " ['it', '-PRON-', 'PRON', ''],\n",
       " [' ', ' ', 'SPACE', ''],\n",
       " ['we', '-PRON-', 'PRON', ''],\n",
       " ['continued', 'continue', 'VERB', ''],\n",
       " ['up', 'up', 'ADP', ''],\n",
       " ['past', 'past', 'ADJ', ''],\n",
       " ['vernal', 'vernal', 'ADJ', ''],\n",
       " ['falls', 'fall', 'NOUN', ''],\n",
       " ['to', 'to', 'ADP', ''],\n",
       " ['nevada', 'nevada', 'PROPN', 'GPE'],\n",
       " ['falls', 'falls', 'PROPN', ''],\n",
       " [' ', ' ', 'SPACE', ''],\n",
       " ['which', 'which', 'DET', ''],\n",
       " ['was', 'be', 'AUX', ''],\n",
       " ['challenging', 'challenge', 'VERB', ''],\n",
       " [' ', ' ', 'SPACE', ''],\n",
       " ['i', 'i', 'PRON', ''],\n",
       " ['do', 'do', 'AUX', ''],\n",
       " ['not', 'not', 'PART', ''],\n",
       " ['advise', 'advise', 'VERB', ''],\n",
       " ['going', 'go', 'VERB', ''],\n",
       " ['down', 'down', 'ADP', ''],\n",
       " ['the', 'the', 'DET', ''],\n",
       " ['mist', 'mist', 'ADJ', ''],\n",
       " ['trail', 'trail', 'NOUN', ''],\n",
       " [' ', ' ', 'SPACE', ''],\n",
       " ['from', 'from', 'ADP', ''],\n",
       " ['nevada', 'nevada', 'PROPN', 'GPE'],\n",
       " ['falls', 'fall', 'VERB', ''],\n",
       " [' ', ' ', 'SPACE', ''],\n",
       " ['if', 'if', 'SCONJ', ''],\n",
       " ['the', 'the', 'DET', ''],\n",
       " ['john', 'john', 'PROPN', 'PERSON'],\n",
       " ['muir', 'muir', 'PROPN', 'PERSON'],\n",
       " ['trail', 'trail', 'PROPN', 'PERSON'],\n",
       " ['loop', 'loop', 'NOUN', 'PERSON'],\n",
       " ['is', 'be', 'AUX', ''],\n",
       " ['not', 'not', 'PART', ''],\n",
       " ['open', 'open', 'ADJ', ''],\n",
       " ['yet', 'yet', 'ADV', ''],\n",
       " [' ', ' ', 'SPACE', ''],\n",
       " ['retrace', 'retrace', 'VERB', ''],\n",
       " ['your', '-PRON-', 'DET', ''],\n",
       " ['steps', 'step', 'NOUN', ''],\n",
       " [' ', ' ', 'SPACE', ''],\n",
       " ['literally', 'literally', 'ADV', ''],\n",
       " [' ', ' ', 'SPACE', ''],\n",
       " ['to', 'to', 'ADP', ''],\n",
       " ['the', 'the', 'DET', ''],\n",
       " ['top', 'top', 'NOUN', ''],\n",
       " ['of', 'of', 'ADP', ''],\n",
       " ['vernal', 'vernal', 'ADJ', ''],\n",
       " ['falls', 'fall', 'NOUN', ''],\n",
       " [' ', ' ', 'SPACE', ''],\n",
       " ['cut', 'cut', 'VERB', ''],\n",
       " ['up', 'up', 'ADP', ''],\n",
       " ['to', 'to', 'ADP', ''],\n",
       " ['clark', 'clark', 'PROPN', ''],\n",
       " ['point', 'point', 'PROPN', ''],\n",
       " [' ', ' ', 'SPACE', ''],\n",
       " ['and', 'and', 'CCONJ', ''],\n",
       " ['then', 'then', 'ADV', ''],\n",
       " ['connect', 'connect', 'VERB', ''],\n",
       " ['with', 'with', 'ADP', ''],\n",
       " ['the', 'the', 'DET', ''],\n",
       " ['john', 'john', 'PROPN', 'PERSON'],\n",
       " ['muir', 'muir', 'PROPN', 'PERSON'],\n",
       " ['trail', 'trail', 'NOUN', ''],\n",
       " ['from', 'from', 'ADP', ''],\n",
       " ['there', 'there', 'ADV', ''],\n",
       " [' ', ' ', 'SPACE', ''],\n",
       " ['its', '-PRON-', 'DET', ''],\n",
       " ['a', 'a', 'DET', ''],\n",
       " ['bit', 'bit', 'NOUN', ''],\n",
       " ['of', 'of', 'ADP', ''],\n",
       " ['another', 'another', 'DET', ''],\n",
       " ['uphill', 'uphill', 'NOUN', ''],\n",
       " ['to', 'to', 'ADP', ''],\n",
       " ['clark', 'clark', 'PROPN', ''],\n",
       " ['point', 'point', 'PROPN', ''],\n",
       " [' ', ' ', 'SPACE', ''],\n",
       " ['but', 'but', 'CCONJ', ''],\n",
       " ['you', '-PRON-', 'PRON', ''],\n",
       " ['ll', 'will', 'VERB', ''],\n",
       " ['appreciate', 'appreciate', 'VERB', ''],\n",
       " ['the', 'the', 'DET', ''],\n",
       " ['easier', 'easy', 'ADJ', ''],\n",
       " ['decent', 'decent', 'ADJ', ''],\n",
       " ['from', 'from', 'ADP', ''],\n",
       " ['there', 'there', 'ADV', '']]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_review_df = df.loc[[3982],'review_text']\n",
    "sample_review = ' '.join(sample_review_df.tolist())\n",
    "\n",
    "sample_review_cleaned = nlp_preprocessing.cleaning(sample_review)\n",
    "\n",
    "spacy_tokens = spacy_nlp(sample_review_cleaned)\n",
    "[[token.text, token.lemma_, token.pos_, token.ent_type_] for token in spacy_tokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the above text, entity labels that equate to 'PERSON', 'LOCATION', 'GPE', 'FAC' or 'ORG' will be removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a better idea of the POS in the corpus, using a couple of random reviews, let's look the words itself, its lemma, and its pos. \n",
    "Based on that we can can decide to only keep certain types of POS for our corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['pm', 'TIME'],\n",
       " ['today', 'DATE'],\n",
       " ['oct', 'DATE'],\n",
       " ['yosemite valley', 'LOC'],\n",
       " ['several miles', 'QUANTITY'],\n",
       " ['yosemite valley', 'LOC'],\n",
       " ['washburn', 'PERSON'],\n",
       " ['about   mile', 'QUANTITY'],\n",
       " ['nevada', 'GPE'],\n",
       " ['half', 'CARDINAL'],\n",
       " ['four mile', 'QUANTITY'],\n",
       " ['yosemite valley', 'LOC'],\n",
       " ['only  feet', 'QUANTITY'],\n",
       " ['a mile', 'QUANTITY'],\n",
       " ['half', 'CARDINAL'],\n",
       " ['year', 'DATE'],\n",
       " ['october', 'DATE'],\n",
       " ['half', 'CARDINAL'],\n",
       " ['half', 'CARDINAL'],\n",
       " ['a few hours', 'TIME'],\n",
       " ['half', 'CARDINAL'],\n",
       " ['yosemite valley', 'LOC'],\n",
       " ['the vista point', 'ORG'],\n",
       " ['half', 'CARDINAL'],\n",
       " ['first', 'ORDINAL'],\n",
       " ['mid summer', 'DATE'],\n",
       " ['nevada', 'GPE'],\n",
       " ['the yosemite park', 'LOC'],\n",
       " ['a typical season', 'DATE'],\n",
       " ['the low season', 'DATE'],\n",
       " ['next year', 'DATE'],\n",
       " ['one', 'CARDINAL'],\n",
       " ['a year or more', 'DATE'],\n",
       " ['a couple of miles', 'QUANTITY'],\n",
       " ['yosemite valley', 'LOC'],\n",
       " ['yosemite valley', 'LOC'],\n",
       " ['nevada', 'GPE'],\n",
       " ['mid august', 'DATE'],\n",
       " ['night', 'TIME'],\n",
       " ['nevada', 'GPE'],\n",
       " ['half', 'CARDINAL'],\n",
       " ['half', 'CARDINAL'],\n",
       " ['el capitan', 'PERSON'],\n",
       " ['coronara', 'ORG'],\n",
       " ['minutes to a half hour', 'TIME'],\n",
       " ['first', 'ORDINAL'],\n",
       " ['second', 'ORDINAL'],\n",
       " ['half', 'CARDINAL'],\n",
       " ['half', 'CARDINAL'],\n",
       " ['el capitan', 'PERSON'],\n",
       " ['nevada', 'GPE'],\n",
       " ['vistas', 'NORP'],\n",
       " ['teh world glacier point', 'FAC'],\n",
       " ['half', 'CARDINAL'],\n",
       " ['nevada', 'GPE'],\n",
       " ['the day', 'DATE'],\n",
       " ['monday', 'DATE'],\n",
       " ['late june', 'DATE'],\n",
       " ['weekends', 'DATE'],\n",
       " ['july', 'DATE'],\n",
       " ['weekday', 'DATE'],\n",
       " ['june', 'DATE'],\n",
       " ['several hours', 'TIME'],\n",
       " ['that day', 'DATE'],\n",
       " ['half', 'CARDINAL']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy_all_reviews = spacy_nlp(all_reviews[:10000])\n",
    "[[ent.text, ent.label_] for ent in spacy_all_reviews.ents]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on perusing the above corpus sample, only 'NOUN', 'VERB' and 'ADJ' will be kept.  \n",
    "Both, entity removal & pos tags can be used to further remove unnecessary words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "pos =  ['NOUN', 'VERB', 'ADJ', 'ADV']\n",
    "ents = ['PERSON', 'LOC', 'GPE', 'FAC', 'ORG']\n",
    "\n",
    "df['review_pos_ent_filter'] = df.reviews_basic_clean.map(lambda x: spacy_pos_filtering(x, pos, ents))\n",
    "df['review_pos_ent_filter'] = df.review_pos_ent_filter.map(lambda x: remove_stopwords(x, sklearn_stop_words ))\n",
    "df['review_pos_ent_filter'] = df.review_pos_ent_filter.map(lambda x: remove_stopwords(x, additional_removal_words ))\n",
    "\n",
    "df[['review_text','review_pos_ent_filter']].sample(2)\n",
    "\n",
    "#Must add method to account for negative modifiers - not, nothing, etc to ensure meaning is preserved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since important modifiers were being dropped using the above method, for now, the corpus will not undergo further pre-processing, involving the aspects defined in the above code block."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Code Snippets for Reference to help with the NLP Pre-processsing steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[&#39;Hi&#39;, &#39;Mr.&#39;, &#39;Smith&#39;, &#39;!&#39;, &#39;I&#39;, &#39;’&#39;, &#39;m&#39;, &#39;going&#39;, &#39;to&#39;, &#39;buy&#39;, &#39;some&#39;, &#39;vegetables&#39;, &#39;(&#39;, &#39;tomatoes&#39;, &#39;and&#39;, &#39;cucumbers&#39;, &#39;)&#39;, &#39;from&#39;, &#39;the&#39;, &#39;store&#39;, &#39;.&#39;, &#39;Should&#39;, &#39;I&#39;, &#39;pick&#39;, &#39;up&#39;, &#39;some&#39;, &#39;black-eyed&#39;, &#39;peas&#39;, &#39;as&#39;, &#39;well&#39;, &#39;?&#39;]\n",
      "[(&#39;Hi&#39;, &#39;Mr.&#39;), (&#39;Mr.&#39;, &#39;Smith&#39;), (&#39;Smith&#39;, &#39;!&#39;), (&#39;!&#39;, &#39;I&#39;), (&#39;I&#39;, &#39;’&#39;), (&#39;’&#39;, &#39;m&#39;), (&#39;m&#39;, &#39;going&#39;), (&#39;going&#39;, &#39;to&#39;), (&#39;to&#39;, &#39;buy&#39;), (&#39;buy&#39;, &#39;some&#39;), (&#39;some&#39;, &#39;vegetables&#39;), (&#39;vegetables&#39;, &#39;(&#39;), (&#39;(&#39;, &#39;tomatoes&#39;), (&#39;tomatoes&#39;, &#39;and&#39;), (&#39;and&#39;, &#39;cucumbers&#39;), (&#39;cucumbers&#39;, &#39;)&#39;), (&#39;)&#39;, &#39;from&#39;), (&#39;from&#39;, &#39;the&#39;), (&#39;the&#39;, &#39;store&#39;), (&#39;store&#39;, &#39;.&#39;), (&#39;.&#39;, &#39;Should&#39;), (&#39;Should&#39;, &#39;I&#39;), (&#39;I&#39;, &#39;pick&#39;), (&#39;pick&#39;, &#39;up&#39;), (&#39;up&#39;, &#39;some&#39;), (&#39;some&#39;, &#39;black-eyed&#39;), (&#39;black-eyed&#39;, &#39;peas&#39;), (&#39;peas&#39;, &#39;as&#39;), (&#39;as&#39;, &#39;well&#39;), (&#39;well&#39;, &#39;?&#39;)]\n",
      "[&#39;Hi&#39;, &#39;Mr.&#39;, &#39;Smith!&#39;, &#39;I’m&#39;, &#39;going&#39;, &#39;to&#39;, &#39;buy&#39;, &#39;some&#39;, &#39;vegetables&#39;, &#39;(tomatoes&#39;, &#39;and&#39;, &#39;cucumbers)&#39;, &#39;from&#39;, &#39;the&#39;, &#39;store.&#39;, &#39;Should&#39;, &#39;I&#39;, &#39;pick&#39;, &#39;up&#39;, &#39;some&#39;, &#39;black-eyed&#39;, &#39;peas&#39;, &#39;as&#39;, &#39;well?&#39;]\n",
      "[&#39;Hi&#39;, &#39;Mr&#39;, &#39;Smith&#39;, &#39;Should&#39;]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "my_text = \"Hi Mr. Smith! I’m going to buy some vegetables (tomatoes and cucumbers) from \\\n",
    "the store. Should I pick up some black-eyed peas as well?\"\n",
    "\n",
    "print(word_tokenize(my_text))\n",
    "\n",
    "# (N-Grams)\n",
    "\n",
    "from nltk.util import ngrams\n",
    "my_words = word_tokenize(my_text) # This is the list of all words\n",
    "twograms = list(ngrams(my_words,2)) # This is for two-word combos, but can pick any n\n",
    "print(twograms)\n",
    "\n",
    "# Regular Expressions\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "# RegexpTokenizer with whitespace delimiter\n",
    "whitespace_tokenizer = RegexpTokenizer(\"\\s+\", gaps=True)\n",
    "print(whitespace_tokenizer.tokenize(my_text))\n",
    "\n",
    "# RegexpTokenizer to match only capitalized words\n",
    "cap_tokenizer = RegexpTokenizer(\"[A-Z]['\\w]+\")\n",
    "print(cap_tokenizer.tokenize(my_text))\n",
    "\n",
    "from nltk.tokenize import regexp_tokenize, wordpunct_tokenize, blankline_tokenize\n",
    "\n",
    "s = \"Good muffins cost $3.88\\nin New York.  Please buy me\\ntwo of them.\\n\\nThanks.\"\n",
    "regexp_tokenize(s, pattern='\\w+|\\$[\\d\\.]+|\\S+')\n",
    "\n",
    "wordpunct_tokenize(s)\n",
    "\n",
    "blankline_tokenize(s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing: Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "set(stopwords.words('english'))\n",
    "\n",
    "#Example impact with code\n",
    "\n",
    "my_text = [\"Hi Mr. Smith! I’m going to buy some vegetables (tomatoes and cucumbers) from \\\n",
    "the store. Should I pick up some black-eyed peas as well?\"]\n",
    "\n",
    "# Incorporate stop words when creating the count vectorizer\n",
    "cv = CountVectorizer(stop_words='english')\n",
    "X = cv.fit_transform(my_text)\n",
    "pd.DataFrame(X.toarray(), columns=cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS Tagging With NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(&#39;James&#39;, &#39;NNP&#39;), (&#39;Smith&#39;, &#39;NNP&#39;), (&#39;lives&#39;, &#39;VBZ&#39;), (&#39;in&#39;, &#39;IN&#39;), (&#39;the&#39;, &#39;DT&#39;), (&#39;United&#39;, &#39;NNP&#39;), (&#39;States&#39;, &#39;NNPS&#39;), (&#39;.&#39;, &#39;.&#39;)]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tag import pos_tag\n",
    "my_text = \"James Smith lives in the United States.\"\n",
    "tokens = pos_tag(word_tokenize(my_text))\n",
    "print(tokens)\n",
    "\n",
    "#For help on the codes, use the below\n",
    "# nltk.help.upenn_tagset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.chunk import ne_chunk\n",
    "my_text = \"James Smith lives in the United States.\"\n",
    "tokens = pos_tag(word_tokenize(my_text)) # this labels each word as a part of speech\n",
    "entities = ne_chunk(tokens) # this extracts entities from the list of words\n",
    "# help(entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compound Term Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You_all are the greatest students of_all_time .'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import MWETokenizer # multi-word expression\n",
    "my_text = \"You all are the greatest students of all time.\"\n",
    "mwe_tokenizer = MWETokenizer([('You','all'), ('of', 'all', 'time')])\n",
    "mwe_tokens = mwe_tokenizer.tokenize(word_tokenize(my_text))\n",
    "' '.join(mwe_tokens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
